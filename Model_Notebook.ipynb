{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS as wc_stp\n",
    "\n",
    "#Sklearn\n",
    "import sklearn.feature_extraction.text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as tvect\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn . decomposition import PCA\n",
    "##Metrics and Testing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "##Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/final_bullying_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Under-Sampling to rebalance the dataset\n",
    "#df.loc[df['oh_label'] == 1.0].count()\n",
    "dfA = df.loc[df['oh_label'] == \"Not Bullying\"]\n",
    "dfB = df.loc[df['oh_label'] == \"Bullying\"]\n",
    "\n",
    "dfA = dfA.sample(n=6000)\n",
    "dfB = dfB.sample(n=5700)\n",
    "\n",
    "df = pd.concat([dfA,dfB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring the data\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "df.groupby('oh_label').Text.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in [\"Not Bullying\",\"Bullying\"]:\n",
    "    text = \"\"\n",
    "    df_wc = df.loc[df['oh_label'] == class_name]\n",
    "    \n",
    "    text = \" \".join(str(x) for x in df_wc[\"Text\"])\n",
    "    \n",
    "    # Generate a word cloud image\n",
    "    wordcloud = WordCloud(background_color=\"white\").generate(text)\n",
    "    \n",
    "    # Display the generated image:\n",
    "    # the matplotlib way:\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(class_name)\n",
    "    plt.show()\n",
    "    \n",
    "    df_wc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Term Frequency Inverse Document Frequency vectorization applied to append numerical values to the text based on \n",
    "#relevance to the document.\n",
    "tv = tvect(min_df=.005, ngram_range=(1,2))\n",
    "X = df['Text']\n",
    "X = tv.fit_transform(X)\n",
    "y = df['oh_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing multiple models at base configuration to see which is best for the task at hand\n",
    "models = [\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(),\n",
    "    SVC(kernel=\"linear\"),\n",
    "    KNeighborsClassifier(n_neighbors=10)\n",
    "]\n",
    "CV = 10\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, X, y, scoring='accuracy', cv=CV)\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show(plt.figure(figsize=(25,10)))\n",
    "print(cv_df.groupby('model_name').accuracy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text']\n",
    "#Crossfold Validation for SVC and tf-idf to tune for hyperparameters\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, df.index, test_size=0.77, random_state=171340)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tv', tvect()),\n",
    "    ('svc', SVC()),\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tv__max_df': [0.8,0.85,0.9],\n",
    "    'tv__min_df': [1,10,100],\n",
    "    'tv__ngram_range': ((1, 1), (1, 2)),\n",
    "    \"svc__kernel\": [\"linear\", \"poly\"],\n",
    "    \"svc__C\": [1,10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, params, verbose=1,n_jobs=-1, cv=3)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(params)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print()\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(params.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text']\n",
    "#Crossfold Validation for LogisticRegression and tf-idf to tune for hyperparameters\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, df.index, test_size=0.77, random_state=171340)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tv', tvect()),\n",
    "    ('lr', LogisticRegression()),\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tv__max_df': [0.7,0.75,0.8,0.85,0.9],\n",
    "    'tv__min_df': [1,10,100],\n",
    "    'tv__ngram_range': ((1, 1), (1, 2)),\n",
    "    \"lr__solver\": ['lbfgs', 'liblinear'],\n",
    "    \"lr__C\": [100, 10, 1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, params, verbose=1,n_jobs=-1, cv=3)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(params)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print()\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(params.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text']\n",
    "#Crossfold Validation for MultinomialNB and tf-idf to tune for hyperparameters\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, df.index, test_size=0.77, random_state=171340)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tv', tvect()),\n",
    "    ('mnb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tv__max_df': [0.7,0.75,0.8,0.85,0.9],\n",
    "    'tv__min_df': [1,10,100],\n",
    "    'tv__ngram_range': ((1, 1), (1, 2)),\n",
    "    \"mnb__alpha\": [1.0, .9, .8, .7, .6]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, params, verbose=1,n_jobs=-1, cv=3)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(params)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print()\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(params.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-economy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the final TF-IDF Vectoriser & the final train/test set\n",
    "tv = tvect(max_df=0.7,min_df=1,ngram_range=(1,2))\n",
    "X = tv.fit_transform(df['Text'])\n",
    "y = df['oh_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the final SVC Model\n",
    "model = SVC(C=1,kernel='linear',probability=True)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "print(model.score(X_test,y_test))\n",
    "ypred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"METRICS FOR SVC\")\n",
    "print(metrics.classification_report(y_test, ypred, target_names=df['oh_label'].unique()))\n",
    "y_true = y_test\n",
    "y_pred = ypred\n",
    "data = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_true), index = np.unique(y_true))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16}, fmt=\"g\")# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the final Linear Regression Model\n",
    "lr_model = LogisticRegression(C=100,solver='lbfgs')\n",
    "\n",
    "lr_model.fit(X_train,y_train)\n",
    "print(lr_model.score(X_test,y_test))\n",
    "ypred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"METRICS FOR Logistic Regression\")\n",
    "print(metrics.classification_report(y_test, ypred, target_names=df['oh_label'].unique()))\n",
    "y_true = y_test\n",
    "y_pred = ypred\n",
    "data = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_true), index = np.unique(y_true))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16}, fmt=\"g\")# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the final MultinomialNB model\n",
    "nb_model = MultinomialNB(alpha=0.6)\n",
    "\n",
    "nb_model.fit(X_train,y_train)\n",
    "print(nb_model.score(X_test,y_test))\n",
    "ypred = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"METRICS FOR MultinomialNB\")\n",
    "print(metrics.classification_report(y_test, ypred, target_names=df['oh_label'].unique()))\n",
    "y_true = y_test\n",
    "y_pred = ypred\n",
    "data = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_true), index = np.unique(y_true))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16}, fmt=\"g\")# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SVC model score = ',model.score(X_test,y_test))\n",
    "print('LogisticRegression model score = ',lr_model.score(X_test,y_test))\n",
    "print('MultinomialNB model score = ',nb_model.score(X_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
